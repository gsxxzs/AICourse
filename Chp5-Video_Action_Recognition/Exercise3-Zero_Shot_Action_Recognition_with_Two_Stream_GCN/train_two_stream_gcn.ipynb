{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/Chp5/Ex3/data_yahoo_100m_v2/ind.ucf101.Yahoo_100m\n",
      "../../data/Chp5/Ex3/data_yahoo_100m_v2/ind.ucf101.labels\n",
      "../../data/Chp5/Ex3/data_yahoo_100m_v2/ind.ucf101.graph_all\n",
      "../../data/Chp5/Ex3/data_yahoo_100m_v2/ind.ucf101.graph_att\n",
      "../../data/Chp5/Ex3/data_yahoo_100m_v2/ind.ucf101.split_train\n",
      "../../data/Chp5/Ex3/data_yahoo_100m_v2/ind.ucf101.split_test\n",
      "../../data/Chp5/Ex3/data_yahoo_100m_v2/ind.ucf101.lookup_table\n",
      "(1689, 500)\n",
      "topK = 50\n",
      "WARNING:tensorflow:From /home/tianyi/python3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/tianyi/Chp5-Video_Action_Recognition/Exercise3:Zero-Shot-Action_Recognition_with_Two_Stream_GCN/models.py:355: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "WARNING:tensorflow:From /home/tianyi/Chp5-Video_Action_Recognition/Exercise3:Zero-Shot-Action_Recognition_with_Two_Stream_GCN/layers.py:176: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/tianyi/Chp5-Video_Action_Recognition/Exercise3:Zero-Shot-Action_Recognition_with_Two_Stream_GCN/metrics.py:97: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "WARNING:tensorflow:From /home/tianyi/Chp5-Video_Action_Recognition/Exercise3:Zero-Shot-Action_Recognition_with_Two_Stream_GCN/metrics.py:110: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From /home/tianyi/Chp5-Video_Action_Recognition/Exercise3:Zero-Shot-Action_Recognition_with_Two_Stream_GCN/metrics.py:142: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.math.argmax` instead\n",
      "WARNING:tensorflow:From /home/tianyi/python3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tianyi/python3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### save to: ./output_models/ucf101\n",
      "### save to: ./results/ucf101/\n",
      "Epoch: 0001 sample_batch: 0001 train_loss= 17.20997 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0002 train_loss= 16.24048 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0003 train_loss= 16.18640 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0004 train_loss= 25.18425 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0005 train_loss= 16.19167 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0006 train_loss= 30.77599 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0007 train_loss= 16.94072 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0008 train_loss= 12.23337 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0009 train_loss= 23.36266 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0010 train_loss= 18.40981 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0011 train_loss= 14.87381 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0012 train_loss= 19.71403 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0013 train_loss= 12.81357 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0014 train_loss= 16.79423 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0015 train_loss= 19.34414 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0016 train_loss= 18.60266 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0017 train_loss= 18.35033 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0018 train_loss= 18.39742 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0019 train_loss= 15.93222 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0020 train_loss= 11.52244 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0021 train_loss= 20.98396 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0022 train_loss= 21.14323 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0023 train_loss= 25.09785 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0024 train_loss= 17.37627 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0025 train_loss= 17.59526 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0026 train_loss= 12.90539 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0027 train_loss= 13.87289 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0028 train_loss= 15.91658 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0029 train_loss= 16.21082 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0030 train_loss= 14.34922 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0031 train_loss= 13.46121 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0032 train_loss= 16.26211 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0033 train_loss= 19.03626 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0034 train_loss= 11.18666 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0035 train_loss= 17.67979 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0036 train_loss= 14.74952 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0037 train_loss= 15.62090 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0038 train_loss= 7.49444 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0039 train_loss= 12.10178 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0040 train_loss= 17.25414 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0041 train_loss= 18.93774 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0042 train_loss= 13.58132 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0043 train_loss= 10.75125 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0044 train_loss= 18.53110 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0045 train_loss= 10.92535 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0046 train_loss= 13.50536 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0047 train_loss= 19.06600 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0048 train_loss= 14.56621 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0049 train_loss= 13.74523 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0050 train_loss= 15.07972 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0051 train_loss= 14.59931 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0052 train_loss= 15.20075 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0053 train_loss= 18.30244 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0054 train_loss= 16.43705 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0055 train_loss= 12.14933 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0056 train_loss= 24.14757 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0057 train_loss= 15.57161 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0058 train_loss= 14.89411 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0059 train_loss= 11.11300 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0060 train_loss= 14.43665 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0061 train_loss= 12.78327 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0062 train_loss= 12.91788 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0063 train_loss= 13.32353 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0064 train_loss= 42.82235 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0065 train_loss= 12.65418 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0066 train_loss= 9.84207 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0067 train_loss= 14.82501 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0068 train_loss= 16.35900 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0069 train_loss= 25.10829 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0070 train_loss= 11.80126 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0071 train_loss= 12.61264 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0072 train_loss= 14.42954 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0073 train_loss= 12.69969 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0074 train_loss= 17.65003 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0075 train_loss= 12.18335 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0076 train_loss= 16.06318 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0077 train_loss= 14.10658 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0078 train_loss= 12.30867 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0079 train_loss= 20.27559 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0080 train_loss= 14.66233 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0081 train_loss= 17.84621 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0082 train_loss= 16.05539 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0083 train_loss= 21.65935 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0084 train_loss= 14.32173 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0085 train_loss= 11.40362 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0086 train_loss= 21.40446 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0087 train_loss= 16.14159 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0088 train_loss= 19.98459 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0089 train_loss= 13.44168 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0090 train_loss= 11.48102 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0091 train_loss= 10.76040 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0092 train_loss= 15.44911 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0093 train_loss= 14.36572 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0094 train_loss= 8.49143 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0095 train_loss= 13.08199 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0096 train_loss= 16.94657 lr= 0.00010\n",
      "Epoch: 0001 sample_batch: 0097 train_loss= 15.21378 lr= 0.00010\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ed1517e26b7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattend_feat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/python3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from utils import *\n",
    "from models import GCN_dense_mse_2s, GCN_dense_mse_2s_little\n",
    "\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    "# Settings\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "\n",
    "flags.DEFINE_string('dataset', 'ucf101', 'Dataset string.') #ucf101, hmdb51, olympic_sports\n",
    "flags.DEFINE_string('w2v_type', 'Yahoo_100m', 'Word2Vec Type.')# Google_News_w2v, Yahoo_100m\n",
    "flags.DEFINE_integer('w2v_dim', 500, 'dimension of the word2vec.')\n",
    "flags.DEFINE_integer('time_interval', 2, 'Number of time interval for a shot.')#64,4,2\n",
    "flags.DEFINE_integer('ini_seg_num', 32, 'Number of initial number of segments.')#64,32\n",
    "flags.DEFINE_integer('num_class', 1588, 'Number of chossen imageNet classes.')# 1588, 2414, 3714, 2271, 3653, 846\n",
    "flags.DEFINE_integer('output_dim', 512, 'Number of units in the last layer (output the classifier).')# 300, 500\n",
    "flags.DEFINE_integer('split_ind', 0, 'current zero-shot split.')\n",
    "flags.DEFINE_integer('topK', 50, 'we choose topK objects for each segment.')# 40, 50, 100, 150, 200\n",
    "flags.DEFINE_bool('use_normalization', 1, 'use_normalization for the classifiers.')\n",
    "flags.DEFINE_bool('use_softmax', 1, 'use softmax or sigmoid for the classification.')\n",
    "flags.DEFINE_bool('use_self_attention', 1, 'use self_attention or not.')\n",
    "flags.DEFINE_integer('label_num', 101, 'number of actions.')\n",
    "flags.DEFINE_integer('batch_size', 4, 'batch size.')\n",
    "flags.DEFINE_string('use_little', 'no_use', 'whether use the little network')# no_use, use_little, use_three_layer\n",
    "flags.DEFINE_string('result_save_path', './results/', 'results save dir')\n",
    "\n",
    " \n",
    "\n",
    "flags.DEFINE_string('model', 'dense', 'Model string.')\n",
    "flags.DEFINE_float('learning_rate', 0.0001, 'Initial learning rate.')#0.001, 0.0001\n",
    "flags.DEFINE_string('save_path', './output_models/', 'save dir')\n",
    "flags.DEFINE_integer('epochs', 5, 'Number of epochs to train.')\n",
    "flags.DEFINE_integer('hidden1', 2048, 'Number of units in hidden layer 1.')# 2048, 1024, 512, 300\n",
    "flags.DEFINE_integer('hidden2', 1024, 'Number of units in hidden layer 1.')\n",
    "flags.DEFINE_float('dropout', 0.5, 'Dropout rate (1 - keep probability).')\n",
    "flags.DEFINE_float('weight_decay', 5e-4, 'Weight for L2 loss on embedding matrix.')\n",
    "flags.DEFINE_integer('early_stopping', 10, 'Tolerance for early stopping (# of epochs).')\n",
    "flags.DEFINE_integer('max_degree', 3, 'Maximum Chebyshev polynomial degree.')\n",
    "flags.DEFINE_string('gpu', '1', 'gpu id')\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = FLAGS.gpu\n",
    "\n",
    "\n",
    "now_time = datetime.datetime.now().strftime('%Y-%m-%d-%T')\n",
    "\n",
    "# Load data\n",
    "data_path = '../../data/Chp5/Ex3/data_yahoo_100m_v2'\n",
    "all_att_inds, all_att_scores = get_imageNet_input_data(FLAGS.dataset, FLAGS.time_interval, FLAGS.ini_seg_num, FLAGS.num_class, root=data_path)#'data_yahoo_100m'\n",
    "adj_all, adj_att, features, y_train, y_val, idx_train, idx_val, train_mask, test_mask, lookup_table = \\\n",
    "        load_data_action_zero_shot(FLAGS.dataset, FLAGS.w2v_type, FLAGS.split_ind, data_path = data_path)#data_yahoo_100m\n",
    "label_num = len(train_mask)\n",
    "FLAGS.label_num = label_num\n",
    "if FLAGS.w2v_type == 'Yahoo_100m':\n",
    "    FLAGS.w2v_dim = 500\n",
    "\n",
    "# Some preprocessing\n",
    "features, div_mat = preprocess_features_dense2(features)\n",
    "features_all = features\n",
    "features_att = features[label_num:,:]\n",
    "\n",
    "if FLAGS.model == 'dense':\n",
    "    support_all = [preprocess_adj(adj_all)]\n",
    "    support_att = [preprocess_adj(adj_att)]\n",
    "    support_att_batch = [preprocess_adj(adj_att)]\n",
    "    for s in range(len(support_att_batch)):\n",
    "        support_att_batch[s] = list(support_att_batch[s])\n",
    "        for i in range(FLAGS.batch_size-1):\n",
    "            support_att_batch[s][0] = np.concatenate((support_att_batch[s][0], support_att[s][0]+(i+1)*FLAGS.num_class))\n",
    "            support_att_batch[s][1] = np.concatenate((support_att_batch[s][1], support_att[s][1]))\n",
    "        support_att_batch[s][2] = tuple(np.array(support_att[s][2])*FLAGS.batch_size)\n",
    "    num_supports = len(support_att)\n",
    "    if FLAGS.use_little == 'use_little':\n",
    "        model_func = GCN_dense_mse_2s_little\n",
    "    else:\n",
    "        model_func = GCN_dense_mse_2s\n",
    "else:\n",
    "    raise ValueError('Invalid argument for model: ' + str(FLAGS.model))\n",
    "\n",
    "print(features.shape)\n",
    "\n",
    "# Define placeholders\n",
    "if FLAGS.use_self_attention:\n",
    "    seg_number = int(FLAGS.ini_seg_num / FLAGS.time_interval)\n",
    "    topK = FLAGS.topK\n",
    "    print('topK = %d' %topK)\n",
    "    tmp_row_index = np.arange(0, seg_number)\n",
    "    tmp_row_index = np.expand_dims(tmp_row_index,1)\n",
    "    tmp_row_index = np.expand_dims(tmp_row_index, 0)\n",
    "    tmp_row_index = np.tile(tmp_row_index,(FLAGS.batch_size,1,topK))\n",
    "    tmp_batch_index = np.arange(0, FLAGS.batch_size)\n",
    "    tmp_batch_index = np.expand_dims(tmp_batch_index, 1)\n",
    "    tmp_batch_index = np.expand_dims(tmp_batch_index, 1)\n",
    "    tmp_batch_index = np.tile(tmp_batch_index, (1, seg_number, topK))\n",
    "    placeholders = {\n",
    "        'support_all': [tf.sparse_placeholder(tf.float32) for _ in range(num_supports)],\n",
    "        'support_att': [tf.sparse_placeholder(tf.float32) for _ in range(num_supports)],\n",
    "        'features_all': tf.placeholder(tf.float32, shape=(features_all.shape[0], features_all.shape[1])),\n",
    "        'features_att': tf.placeholder(tf.float32, shape=(FLAGS.batch_size, seg_number, 1, features_att.shape[0])),\n",
    "        'labels': tf.placeholder(tf.int32, shape=(FLAGS.batch_size)),\n",
    "        'train_mask': tf.placeholder(tf.int32, shape=(train_mask.shape[0])),\n",
    "        'dropout': tf.placeholder_with_default(0., shape=()),\n",
    "        'num_features_nonzero': tf.placeholder(tf.int32),  # helper variable for sparse dropout\n",
    "        'learning_rate': tf.placeholder(tf.float32, shape=()),\n",
    "        'label_num': tf.placeholder(tf.int32, shape=())\n",
    "    }\n",
    "else:\n",
    "    placeholders = {\n",
    "        'support_all': [tf.sparse_placeholder(tf.float32) for _ in range(num_supports)],\n",
    "        'support_att': [tf.sparse_placeholder(tf.float32) for _ in range(num_supports)],\n",
    "        'features_all': tf.placeholder(tf.float32, shape=(features_all.shape[0], features_all.shape[1])),\n",
    "        'features_att': tf.placeholder(tf.float32, shape=(features_att.shape[0], features_att.shape[1])),\n",
    "        'labels': tf.placeholder(tf.int32),\n",
    "        'train_mask': tf.placeholder(tf.int32, shape=(train_mask.shape[0])),\n",
    "        'dropout': tf.placeholder_with_default(0., shape=()),\n",
    "        'num_features_nonzero': tf.placeholder(tf.int32),  # helper variable for sparse dropout\n",
    "        'learning_rate': tf.placeholder(tf.float32, shape=()),\n",
    "        'label_num': tf.placeholder(tf.int32, shape=())\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# Create model\n",
    "lookup_table_act_att = tf.SparseTensor(indices=lookup_table[0], values=lookup_table[1], dense_shape=lookup_table[2])\n",
    "model = model_func(placeholders, lookup_table_act_att, input_dim=features.shape[1], logging=True)\n",
    "\n",
    "sess = tf.Session(config=create_config_proto())\n",
    "\n",
    "# Init variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "savepath = FLAGS.save_path\n",
    "exp_name = os.path.basename(FLAGS.dataset)\n",
    "savepath = os.path.join(savepath, exp_name)\n",
    "if not os.path.exists(savepath):\n",
    "    os.makedirs(savepath)\n",
    "    print('!!! Make directory %s' % savepath)\n",
    "else:\n",
    "    print('### save to: %s' % savepath)\n",
    "\n",
    "result_save_path = FLAGS.result_save_path + FLAGS.dataset + '/'\n",
    "if not os.path.exists(result_save_path):\n",
    "    os.makedirs(result_save_path)\n",
    "    print('!!! Make directory %s' % result_save_path)\n",
    "else:\n",
    "    print('### save to: %s' % result_save_path)\n",
    "result_file_name = result_save_path + FLAGS.dataset + '_' + FLAGS.w2v_type + '_' \\\n",
    "                    + str(FLAGS.time_interval) + '_' + str(FLAGS.ini_seg_num) \\\n",
    "                   + '_' + str(FLAGS.num_class) + '_' + FLAGS.use_little  \\\n",
    "                   + str(int(FLAGS.learning_rate *100000))+ '_' + str(FLAGS.hidden1) + '_' \\\n",
    "                   + str(FLAGS.output_dim) + '_' + str(FLAGS.use_normalization)+ '_'\\\n",
    "                   + str(FLAGS.use_softmax) + '_' + str(FLAGS.split_ind) + '_' \\\n",
    "                   + str(FLAGS.use_self_attention) + '_' + str(FLAGS.batch_size) + '_' \\\n",
    "                    + str(FLAGS.hidden2) + '.txt'\n",
    "\n",
    "# Train model\n",
    "now_lr = FLAGS.learning_rate\n",
    "y_train = np.array(y_train)\n",
    "idx_train = np.array(idx_train)\n",
    "y_val = np.array(y_val)\n",
    "idx_val = np.array(idx_val)\n",
    "all_att_inds = np.array(all_att_inds)\n",
    "all_att_scores = np.array(all_att_scores)\n",
    "for epoch in range(FLAGS.epochs):\n",
    "    count = 0\n",
    "    rand_inds = np.random.permutation(len(y_train))\n",
    "    rand_inds = rand_inds[:int(len(rand_inds)/FLAGS.batch_size)*FLAGS.batch_size]\n",
    "    rand_inds = np.reshape(rand_inds,[-1, FLAGS.batch_size])\n",
    "    for inds in rand_inds[:int(len(rand_inds)/5)]:\n",
    "        # Construct feed dictionary\n",
    "        label = y_train[inds]\n",
    "        video_idx = idx_train[inds]\n",
    "        if FLAGS.use_self_attention:\n",
    "            features_att_this_sample = np.zeros([FLAGS.batch_size,seg_number,FLAGS.num_class])\n",
    "            att_ind = all_att_inds[video_idx]\n",
    "            att_score = all_att_scores[video_idx]\n",
    "            att_ind = att_ind[:,:, :topK]\n",
    "            att_score = att_score[:,:, :topK]\n",
    "            features_att_this_sample[tmp_batch_index,tmp_row_index, att_ind] = att_score\n",
    "            features_att_this_sample = np.expand_dims(features_att_this_sample, 2)\n",
    "        else:\n",
    "            att_ind = all_att_inds[video_idx]\n",
    "            att_score = all_att_scores[video_idx]\n",
    "            att_ind = att_ind[:, :topK]\n",
    "            att_score = att_score[:, :topK]\n",
    "            att_activation = get_att_input_activation(att_ind, att_score, FLAGS.num_class, features_att.shape[1])\n",
    "            features_att_this_sample = np.multiply(features_att, att_activation) # Note here we multiply the att scores and the att features\n",
    "        feed_dict = construct_feed_dict(features_all, features_att_this_sample, support_all, support_att_batch, label, train_mask, label_num, placeholders)\n",
    "        feed_dict.update({placeholders['learning_rate']: now_lr})\n",
    "\n",
    "\n",
    "        outs = sess.run([model.opt_op, model.loss, model.optimizer._lr, model.accuracy, model.classifier, model.attend_feat], feed_dict=feed_dict)\n",
    "\n",
    "        if count % 1 == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch + 1),\n",
    "                  \"sample_batch:\", '%04d' % (count + 1), \"train_loss=\", \"{:.5f}\".format(outs[1]),\n",
    "                  \"lr=\", \"{:.5f}\".format(float(outs[2])))\n",
    "            count += 1\n",
    "    # model.save(sess=sess, save_path=savepath)\n",
    "    test_accuracy = 0\n",
    "    test_inds = np.arange(len(y_val))\n",
    "    test_inds = test_inds[:int(len(test_inds) / FLAGS.batch_size) * FLAGS.batch_size]\n",
    "    test_inds = np.reshape(test_inds, [-1, FLAGS.batch_size])\n",
    "    count_test = 0\n",
    "    for inds in test_inds:\n",
    "        # Construct feed dictionary\n",
    "        label = y_val[inds]\n",
    "        video_idx = idx_val[inds]\n",
    "        if FLAGS.use_self_attention:\n",
    "            features_att_this_sample = np.zeros([FLAGS.batch_size, seg_number, FLAGS.num_class])\n",
    "            att_ind = all_att_inds[video_idx]\n",
    "            att_score = all_att_scores[video_idx]\n",
    "            att_ind = att_ind[:, :, :topK]\n",
    "            att_score = att_score[:, :, :topK]\n",
    "            features_att_this_sample[tmp_batch_index, tmp_row_index, att_ind] = att_score\n",
    "            features_att_this_sample = np.expand_dims(features_att_this_sample, 2)\n",
    "        else:\n",
    "            att_ind = all_att_inds[video_idx]\n",
    "            att_score = all_att_scores[video_idx]\n",
    "            att_ind = att_ind[:, :topK]\n",
    "            att_score = att_score[:, :topK]\n",
    "            att_activation = get_att_input_activation(att_ind, att_score, FLAGS.num_class, features_att.shape[1])\n",
    "            features_att_this_sample = np.multiply(features_att, att_activation) # Note here we multiply the att scores and the att features\n",
    "        feed_dict = construct_feed_dict(features_all, features_att_this_sample, support_all, support_att_batch, label,\n",
    "                                        test_mask, label_num, placeholders)\n",
    "\n",
    "        # Test step\n",
    "        out = sess.run(model.accuracy, feed_dict=feed_dict)\n",
    "        test_accuracy += np.sum(np.array(out[0]))\n",
    "        count_test += 1\n",
    "        if count_test % 10 == 0:\n",
    "            print('%04d baches are processed for testing' % (count_test ))\n",
    "    test_accuracy /= len(y_val)\n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1),\n",
    "          \"accuracy=\", \"{:.5f}\".format(float(test_accuracy)),\n",
    "          )\n",
    "    with open(result_file_name, 'a') as f:\n",
    "        f.write(str(test_accuracy)+'\\n')\n",
    "\n",
    "\n",
    "print(\"Optimization Finished!\")\n",
    "\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
