{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction using HOG\n",
    "This notebook uses HOG to extract features from the ciphar10 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tianyi/python3/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import the functions to calculate feature descriptions\n",
    "from skimage.feature import hog\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "# To read image file and save image feature descriptions\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "import pickle as pk\n",
    "from config import *\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reads the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../../data/Chp3/3.1/cifar-10-batches-py'\n",
    "\n",
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    dict = pk.load(fo, encoding='bytes')\n",
    "    fo.close()\n",
    "    return dict\n",
    "\n",
    "def getData(filePath):\n",
    "    TrainData = []\n",
    "    for childDir in os.listdir(filePath):\n",
    "        if childDir != 'test_batch':\n",
    "            f = os.path.join(filePath, childDir)\n",
    "            data = unpickle(f)\n",
    "            #train = np.reshape(data[str.encode('data')], (10000, 3, 32 * 32))\n",
    "            # If your python version do not support to use this way to transport str to bytes.\n",
    "            # Think another way and you can.\n",
    "            train = np.reshape(data[b'data'], (10000, 3, 32 * 32))\n",
    "            labels = np.reshape(data[b'labels'], (10000, 1))\n",
    "            fileNames = np.reshape(data[b'filenames'], (10000, 1))\n",
    "            datalebels = zip(train, labels, fileNames)\n",
    "            TrainData.extend(datalebels)\n",
    "        else:\n",
    "            f = os.path.join(filePath, childDir)\n",
    "            data = unpickle(f)\n",
    "            test = np.reshape(data[b'data'], (10000, 3, 32 * 32))\n",
    "            labels = np.reshape(data[b'labels'], (10000, 1))\n",
    "            fileNames = np.reshape(data[b'filenames'], (10000, 1))\n",
    "            TestData = zip(test, labels, fileNames)\n",
    "    return TrainData, TestData\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract and Save Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test features are extracted and saved.\n"
     ]
    }
   ],
   "source": [
    "def getFeat(TrainData, TestData):\n",
    "    for data in TestData:\n",
    "        image = np.reshape(data[0].T, (32, 32, 3))\n",
    "        gray = rgb2gray(image)/255.0\n",
    "        fd = hog(gray, orientations, pixels_per_cell, cells_per_block)\n",
    "        fd = np.concatenate((fd, data[1]))\n",
    "        filename = list(data[2])\n",
    "        fd_name = str(filename[0], encoding = \"utf-8\") .split('.')[0]+'.feat'\n",
    "        fd_path = os.path.join('./data/features/test/', fd_name)\n",
    "        joblib.dump(fd, fd_path)\n",
    "    print(\"Test features are extracted and saved.\")\n",
    "    \n",
    "    for data in TrainData:\n",
    "        image = np.reshape(data[0].T, (32, 32, 3)) #image represented as a 32X32X3 tensor (the 3 comes from the 3 colors)\n",
    "        gray = rgb2gray(image)/255.0 #gray scale the image\n",
    "        fd = hog(gray, orientations, pixels_per_cell, cells_per_block)\n",
    "        #apply HOG\n",
    "        fd = np.concatenate((fd, data[1]))\n",
    "        filename = list(data[2])\n",
    "        fd_name = str(filename[0], encoding=\"utf-8\") .split('.')[0]+'.feat'\n",
    "        fd_path = os.path.join('./data/features/train/', fd_name)\n",
    "        joblib.dump(fd, fd_path)\n",
    "    print(\"Train features are extracted and saved.\")\n",
    "\n",
    "def rgb2gray(im): #grey scale image\n",
    "    gray = im[:, :, 0]*0.2989+im[:, :, 1]*0.5870+im[:, :, 2]*0.1140\n",
    "    return gray\n",
    "\n",
    "def extractFeatures(path):\n",
    "    t0 = time.time()\n",
    "    filePath = path #path to data \n",
    "    TrainData, TestData = getData(filePath)\n",
    "    getFeat(TrainData, TestData)\n",
    "    t1 = time.time()\n",
    "    print(\"Features are extracted and saved.\")\n",
    "    print('The cast of time is:%f'%(t1-t0))\n",
    "    \n",
    "extractFeatures(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
